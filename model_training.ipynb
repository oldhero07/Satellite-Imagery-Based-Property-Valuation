{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Training & Evaluation\n",
                "\n",
                "This notebook trains a Multimodal Regression Model (Satellite Images + Tabular Data) to predict property prices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'pandas'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "import cv2\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models, applications\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Constants\n",
                "IMAGE_DIR = \"satellite_images\"\n",
                "IMG_SIZE = (224, 224)\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 10  # Adjustable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data\n",
                "train_df = pd.read_excel('train.xlsx')\n",
                "test_df = pd.read_excel('test.xlsx')\n",
                "\n",
                "# Preprocessing Tabular Data\n",
                "numerical_cols = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
                "\n",
                "# Handle missing if any (fill with 0 or mean)\n",
                "train_df[numerical_cols] = train_df[numerical_cols].fillna(0)\n",
                "test_df[numerical_cols] = test_df[numerical_cols].fillna(0)\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_train_num = scaler.fit_transform(train_df[numerical_cols])\n",
                "y_train = train_df['price'].values\n",
                "\n",
                "X_test_num = scaler.transform(test_df[numerical_cols])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data Generator\n",
                "class MultimodalDataGenerator(tf.keras.utils.Sequence):\n",
                "    def __init__(self, ids, num_data, labels=None, batch_size=32, img_dir=IMAGE_DIR, dim=(224, 224)):\n",
                "        self.ids = ids\n",
                "        self.num_data = num_data\n",
                "        self.labels = labels\n",
                "        self.batch_size = batch_size\n",
                "        self.img_dir = img_dir\n",
                "        self.dim = dim\n",
                "        self.on_epoch_end()\n",
                "\n",
                "    def __len__(self):\n",
                "        return int(np.ceil(len(self.ids) / self.batch_size))\n",
                "\n",
                "    def __getitem__(self, index):\n",
                "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
                "        ids_temp = [self.ids[k] for k in indexes]\n",
                "        \n",
                "        X_img, X_num = self.__data_generation(ids_temp, indexes)\n",
                "        \n",
                "        if self.labels is not None:\n",
                "            y = self.labels[indexes]\n",
                "            return [X_num, X_img], y\n",
                "        else:\n",
                "            return [X_num, X_img]\n",
                "\n",
                "    def on_epoch_end(self):\n",
                "        self.indexes = np.arange(len(self.ids))\n",
                "        if self.labels is not None:\n",
                "             np.random.shuffle(self.indexes)\n",
                "\n",
                "    def __data_generation(self, ids_temp, indexes):\n",
                "        # Initialization\n",
                "        X_img = np.empty((len(ids_temp), *self.dim, 3))\n",
                "        X_num = self.num_data[indexes]\n",
                "\n",
                "        for i, ID in enumerate(ids_temp):\n",
                "            img_path = os.path.join(self.img_dir, f\"{ID}.jpg\")\n",
                "            if os.path.exists(img_path):\n",
                "                img = cv2.imread(img_path)\n",
                "                if img is not None:\n",
                "                    img = cv2.resize(img, self.dim)\n",
                "                    img = img / 255.0  # Normalize\n",
                "                else:\n",
                "                    img = np.zeros((*self.dim, 3)) # Black image fallback\n",
                "            else:\n",
                "                img = np.zeros((*self.dim, 3)) # Black image fallback\n",
                "            X_img[i,] = img\n",
                "\n",
                "        return X_img, X_num"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split Train/Val\n",
                "X_num_train, X_num_val, y_train_split, y_val_split, id_train, id_val = train_test_split(\n",
                "    X_train_num, y_train, train_df['id'].values, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "train_gen = MultimodalDataGenerator(id_train, X_num_train, y_train_split, BATCH_SIZE)\n",
                "val_gen = MultimodalDataGenerator(id_val, X_num_val, y_val_split, BATCH_SIZE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build Model\n",
                "def create_multimodal_model():\n",
                "    # Numerical Branch\n",
                "    input_num = layers.Input(shape=(X_train_num.shape[1],))\n",
                "    x_num = layers.Dense(128, activation='relu')(input_num)\n",
                "    x_num = layers.Dropout(0.3)(x_num)\n",
                "    x_num = layers.Dense(64, activation='relu')(x_num)\n",
                "\n",
                "    # Image Branch\n",
                "    input_img = layers.Input(shape=(224, 224, 3))\n",
                "    # Using a simple CNN for speed, can swap with EfficientNetB0\n",
                "    x_img = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
                "    x_img = layers.MaxPooling2D((2, 2))(x_img)\n",
                "    x_img = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x_img)\n",
                "    x_img = layers.MaxPooling2D((2, 2))(x_img)\n",
                "    x_img = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x_img)\n",
                "    x_img = layers.Flatten()(x_img)\n",
                "    x_img = layers.Dense(64, activation='relu')(x_img)\n",
                "\n",
                "    # Fusion\n",
                "    combined = layers.concatenate([x_num, x_img])\n",
                "    z = layers.Dense(128, activation='relu')(combined)\n",
                "    z = layers.Dense(64, activation='relu')(z)\n",
                "    output = layers.Dense(1, activation='linear')(z)\n",
                "\n",
                "    model = models.Model(inputs=[input_num, input_img], outputs=output)\n",
                "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
                "    return model\n",
                "\n",
                "model = create_multimodal_model()\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train\n",
                "history = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate Predictions\n",
                "test_gen = MultimodalDataGenerator(test_df['id'].values, X_test_num, batch_size=BATCH_SIZE, labels=None, dim=(224,224))\n",
                "predictions = model.predict(test_gen)\n",
                "\n",
                "submission_df = pd.DataFrame({'id': test_df['id'], 'predicted_price': predictions.flatten()})\n",
                "submission_df.to_csv('enrollno_final.csv', index=False)\n",
                "print(\"Saved predictions to enrollno_final.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Grad-CAM Implementation\n",
                "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
                "    # Create a model that maps the input image to the activations of the last conv layer\n",
                "    # as well as the output predictions\n",
                "    \n",
                "    # Filter layers to find the image branch part up to the last conv layer\n",
                "    # Since we can't easily extract sub-graph from Functional API without names,\n",
                "    # we relies on the fact that we can tap into the tensor graph.\n",
                "    \n",
                "    grad_model = models.Model(\n",
                "        [model.inputs[0], model.inputs[1]], [model.get_layer(last_conv_layer_name).output, model.output]\n",
                "    )\n",
                "\n",
                "    with tf.GradientTape() as tape:\n",
                "        last_conv_layer_output, preds = grad_model([img_array[0], img_array[1]])\n",
                "        if pred_index is None:\n",
                "            pred_index = 0 # Single output\n",
                "        class_channel = preds[:, pred_index]\n",
                "\n",
                "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
                "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
                "\n",
                "    last_conv_layer_output = last_conv_layer_output[0]\n",
                "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
                "    heatmap = tf.squeeze(heatmap)\n",
                "\n",
                "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
                "    return heatmap.numpy()\n",
                "\n",
                "# Find last conv layer\n",
                "last_conv_layer = None\n",
                "for layer in model.layers:\n",
                "    if 'conv2d' in layer.name:\n",
                "        last_conv_layer = layer.name\n",
                "# Use the last one found\n",
                "print(f\"Using layer {last_conv_layer} for Grad-CAM\")\n",
                "\n",
                "if last_conv_layer:\n",
                "    # Visualize for a sample\n",
                "    try:\n",
                "        sample_idx = 0\n",
                "        # Get batches\n",
                "        X_batch, y_batch = val_gen[0]\n",
                "        sample_num = X_batch[0][sample_idx:sample_idx+1] # Shape (1, 17)\n",
                "        sample_img = X_batch[1][sample_idx:sample_idx+1] # Shape (1, 224, 224, 3)\n",
                "\n",
                "        # Generate Heatmap\n",
                "        heatmap = make_gradcam_heatmap([sample_num, sample_img], model, last_conv_layer)\n",
                "\n",
                "        # Display\n",
                "        plt.figure(figsize=(10, 5))\n",
                "        plt.subplot(1, 2, 1)\n",
                "        plt.imshow(sample_img[0])\n",
                "        plt.title(\"Original Image\")\n",
                "        plt.subplot(1, 2, 2)\n",
                "        plt.imshow(heatmap)\n",
                "        plt.title(\"Grad-CAM Heatmap\")\n",
                "        plt.show()\n",
                "    except Exception as e:\n",
                "        print(f\"Grad-CAM Error: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
